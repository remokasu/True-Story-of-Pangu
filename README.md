# 盘古之殇：ファーウェイ 大規模言語モデル研究開発の辛酸と暗黒

皆さん、こんにちは。

私は、ファーウェイのノアズアーク研究所の従業員であり、盤古(Pangu)大規模言語モデルチームに所属しています。

まず身元証明のため、いくつかの詳細を列挙する。

1. 現ノア所長、元アルゴリズム応用部部長、後に小規模モデル実験室に改名された所長の王雲鶴。前ノア所長：姚駿（皆が姚先生と呼ぶ）。各実験室所長：唐睿明（明哥、明隊、既に退職）、尚利峰、張維（維哥）、郝建業（郝先生）、劉武龍（武龍所と呼ばれる）など。その他の中核メンバーや専門家も続々と退職している。
2. 我々は「四野」という組織に所属している。四野の下には多くの部隊があり、基盤言語モデルチームは四縦。王雲鶴の小規模モデルチームは十六縦隊。我々は蘇州での合宿に参加し、様々な月次マイルストーンがある。蘇州攻関会でミッション指令を発布し、マイルストーン前に目標達成が必要。蘇州合宿は各地の人員を蘇州研究所に集中させ、普段はホテル住まい、例えば甪直（ろっちょく）のホテルで、家族や子供とは離ればなれ。
3. 蘇州集結時は土曜日もデフォルトで出勤、非常に辛い。ただし土曜日にはアフタヌーンティーがあり、一度は小龍蝦もあった。蘇州研究所の席は一度移転し、一つの棟から別の棟へ。蘇州研究所の建物はすべてヨーロッパ風装飾で、入口に大きな坂があり、内部の景色は素晴らしい。蘇州集結は通常最低一週間、さらに長期間で、多い人は一、二ヶ月も家に帰れない。
4. ノアはかつて研究型と言われていたが、来てみると四野で大規模言語モデルプロジェクトをやるため、プロジェクトメンバーは完全に納品型になり、会議、審査、報告に満ちている。実験をするのも申請が必要なことが多い。チームは端末Xiaoyi（小芸）、ファーウェイクラウド、ICTなど多数の事業部と連携する必要があり、納品プレッシャーは小さくない。
5. ノア研究開発の盤古モデルの初期内部コードネームは「盤古智子」と呼ばれ、最初は内部申請試用のウェブ版のみで、後にプレッシャーによりWeLinkで統合し公開テストを開始。

この数日、盤古大規模言語モデルが千問(Qwen)を盗用したという疑惑で騒然としている。盤古チームのメンバーとして、私は最近夜な夜な寝返りを打ち、眠れない日々を送っている。盤古のブランドがこれほど大きな影響を受け、一方では、私は利己的に自分のキャリア発展を心配し、過去に努力した仕事が報われないと感じている。もう一方では、誰かがこれらのことを暴露し始めたため、内心では大いに溜飲を下げている。どれほど多くの日夜、我々は内部の一部の人々が繰り返し偽造によって無数の利益を得る行為に歯噛みしながらも無力であった。この抑圧と屈辱は徐々に私のファーウェイへの感情をすり減らし、ここでの日々を次第に漫然と過ごし、迷い戸惑い、しばしば自分の人生と自己価値を疑うようになった。

私は自分が臆病者であることを認める。一介の労働者として、私は王雲鶴など内部で手腕を振るう人々と対立することを恐れるだけでなく、ファーウェイのような巨大企業と対立することをさらに恐れている。私は職を失うことをとても恐れている。結局、私にも家族と子供がいるからだ。だから私は心から内部告発者を尊敬している。しかし、内部がまだ事実を隠蔽し公衆を欺こうとしているのを見ると、私は本当に我慢できなくなった。私も一度勇敢になり、自分の本心に従いたい。刺し違えてでも一矢報いたい。私は自分がここで見聞きしたこと（一部は同僚からの証言）を公表することを決めた。盤古大規模言語モデルの「伝説的物語」について...

ファーウェイは確かに主に昇騰(Ascend)チップで大規模言語モデルを学習している（小規模モデル実験室にはNVIDIAのカードもかなりあり、以前は学習に使っていたが、後に昇騰に移行）。かつて私はファーウェイの「世界第二の選択肢を作る」という決意に感服し、私自身もかつてファーウェイに深い愛着を抱いていた。我々は昇騰と一歩一歩這い上がり、バグだらけの状態から現在モデルを学習できるまで、巨大な労力と犠牲を払った。

最初、私たちの計算力は非常に限られており、910A上でモデルを訓練していた。当時はfp16のみをサポートしており、訓練の安定性はbf16には遠く及ばなかった。盤古のMoEは非常に早く始まり、2023年には主に38B MoEモデルとその後の71B denseモデルを訓練していた。71Bのdenseモデルはパラメータ拡張により第一世代の135B denseモデルとなり、その後、主力モデルも徐々に910B上で訓練されるようになった。

71Bと135Bモデルには、どちらもtokenizerという巨大な致命的欠陥があった。当時使用していたtokenizerはエンコード効率が極めて低く、個々の記号、数字、スペース、さらには漢字一文字ごとに1つのトークンを占有していた。これが計算力を非常に無駄にし、モデルの効果を著しく悪化させることは想像に難くない。ちょうどその時、小型モデル実験室が独自に訓練した語彙表を持っていた。姚先生は当時、モデルのtokenizerが良くないのではないかと疑っていた（事後的に見れば、彼の疑いは間違いなく正しかった）。そこで、小型モデル実験室がかつて試したことがあるということで、71Bと135Bのtokenizerを変更することを決定した。チームは2つのtokenizerを継ぎ接ぎし、tokenizerの変更を開始した。71Bモデルの変更は失敗したが、135Bはより精密なembedding初期化戦略を採用し、少なくとも1Tのデータで継続訓練した後、語彙表の変更にようやく成功した。しかし想像できるように、効果が良くなることはなかった。

この同時期、阿里巴巴(Alibaba)や智譜（Zhipu）など国内他社はGPUで学習し、既に正しい方法を模索していたため、盤古と競合他社の差はますます大きくなった。内部の2300億パラメータをフルスクラッチで学習するDense型モデルも様々な理由で学習に失敗し、プロジェクトの状況はほぼ絶境に陥った。いくつかのマイルストーンのプレッシャーと内部の盤古への強烈な疑問に直面した時、チームの士気は極限まで低迷した。チームは計算資源が極めて限られた中で、多くの努力と奮闘をした。例えば、チームは偶然当時の380億パラメータMoEが期待していたMoEの効果を得ていないことを発見した。そこでMoEパラメータを除去し、130億パラメータのDense型モデルに復元した。380億パラメータのMoEは極めて初期のPangu Alpha 130億に由来するため、アーキテクチャが相対的に遅れており、チームは一連の改良を行った。例えば絶対位置エンコーディングからRoPEへの切り替え、バイアスの除去、RMSNormへの切り替え。同時にトークナイザーのいくつかの失敗と語彙辞書変更の経験を踏まえ、このモデルの語彙辞書も王雲鶴の小規模モデル実験室70億パラメータモデルが使用していた語彙辞書に交換した。後にこの130億パラメータモデルはスケールアップして継続事前学習され、第二世代380億パラメータDense型モデル（数ヶ月間このモデルは主要な盤古ミドルレンジモデルであった）になり、かつて一定の競争力を持っていた。しかし、より大きな1350億パラメータモデルはアーキテクチャが遅れており、語彙辞書変更でモデルが大きく損傷し（後の分析で当時変更した継ぎ接ぎ語彙辞書にはより深刻なバグがあることが判明）、継続事前学習後も千問(Qwen)など当時国内先進モデルと大きな差があった。この時、内部の疑問の声と指導者のプレッシャーもますます大きくなった。チームの状態はほぼ絶境に陥った。

この状況下で、王雲鶴と彼の小規模モデル実験室が乗り出した。彼らは旧1350億パラメータモデルから継承改造したと表明し、短い数百億トークンのデータを学習しただけで、各項目指標が平均10ポイント程度向上したとした。実際、これは彼らが他社の大規模言語モデルに薄皮を被せて応用した第一回の傑作だった。ファーウェイは素人が玄人を指導する体制のため、指導者はこのような馬鹿げたことに全く理解がなく、何らかのアルゴリズム革新があったに違いないと思うだけだった。内部分析を経て、彼らは実際にはQwen 1.5の1100億パラメータモデルを継続事前学習したもので、層の追加、FFN次元の拡張、盤古π論文の一部メカニズム追加により、約1350億パラメータを揃えたものだった。実際、旧1350億パラメータモデルは107層だったが、このモデルは82層のみで、各種設定も全て異なっていた。新しい出所不明の1350億パラメータモデルは学習完了後、多くのパラメータ分布もQwen 1100億パラメータモデルとほぼ同一だった。モデルコードのクラス名は当時すべてQwenで、名前を変更するのも面倒がった。後にこのモデルは所謂1350億パラメータ V2となった。そしてこのモデルは当時多くの下流タスク、さらには外部顧客にも提供された。

この事件は我々のような真面目で誠実に仕事をする同僚たちに巨大な衝撃をもたらした。内部の多くの人、さらには端末事業部やファーウェイクラウド事業部を含めて実はこの事を知っていた。我々は皆冗談で今後盤古モデルと呼ぶのは止めて、千古（Qwen＋Pangu）と呼ぼうと言った。当時チームメンバーはBCG（企業倫理違反通報制度）に通報しようと思った。結局これは既に重大な業務偽造だったからだ。しかし後に上層部に止められたと言われている。より上級レベルの指導者（例えば姚先生、そして恐らく熊総と査老）も実は後に知ったが、問題視しなかった。他社モデルに薄皮を被せて良い結果を出すことは、彼らにとっても都合が良かったからだ。この事により当時チームの最も優秀な数名の同僚が意気消沈し、退職して逃げ出すことも徐々に口癖になった。

この時、盤古は転機を迎えたかのように見えた。前述のこれらの盤古モデルは基本的にすべて継続訓練と改造によるものであり、当時ノアは一から訓練する技術を全く掌握していなかった。ましてや昇騰のNPU上での訓練となればなおさらだった。当時のチームの中核メンバーの懸命な働きかけにより、盤古は第三世代モデルの訓練を開始した。巨大な努力を払った後、データアーキテクチャと訓練アルゴリズムの両面で業界標準に徐々に追いついていった。しかし、この中での苦労と小型モデル実験室の人々は一切関係がなかった。

最初、チームメンバーは全く自信がなく、わずか13Bのモデルから訓練を始めたが、後に効果がなかなか良いことが分かった。そこで、このモデルはその後もう一度パラメータ拡張を行い、第三世代の38Bとなった。コードネームは38B V3である。おそらく多くの製品ラインの仲間たちがこのモデルをよく知っているだろう。当時このモデルのtokenizerはllamaの語彙表を基に拡張したものだった（これも業界でよく見られるやり方である）。一方、当時王雲鶴の実験室は別の語彙表を作り出していた（これが後のpanguシリーズの語彙表となる）。当時、二つの語彙表は競争させられ、最終的に明確な優劣の結論は出なかった。そこで、上層部はその場で決定を下した：語彙表を統一し、王雲鶴たちのものを使用すべきだと。こうして、その後一から訓練された135B V3（対外的にはPangu Ultra）は、このtokenizerを採用することになった。これは、我々のモデルを使用している多くの仲間たちの疑問を説明するものでもある。なぜ当時同じV3世代の二つの異なるサイズのモデルが、異なるtokenizerを使用していたのかという疑問である。


我々は心から、135B V3は我々四縦チームの当時の誇りだと思っている。これは真の意味で初めての、ファーウェイによるフルスタック自主研究、正真正銘一から訓練した100B規模レベルのモデルで、性能は24年同期の競合他社と比較可能だった。ここまで書いて私は既に涙が溢れている。本当に容易ではなかった。当時安定学習のため、チームは大量の実験比較を行い、モデル勾配に異常が現れた時に何度も適時にロールバックして再起動を行った。このモデルは真に後の技術報告で述べられた学習全過程で損失の急激な増加が一度もなかったことを実現した。我々はどれほど多くの困難を克服したか分からない。我々はやり遂げた。我々は生命と名誉をかけてこのモデル学習の真実性を保証する。どれほど多くの夜明け、我々はその学習のために眠らなかった。内部の匿名掲示板で一銭の価値もないと罵られた時、我々はどれほど悔しく、どれほどの屈辱があったか。それでも我々は耐え抜いた。

我々一同は真に国産計算基盤を磨き上げるために自分の青春を燃やしているのだ...故郷を離れ、我々は家庭を犠牲にし、休日を犠牲にし、健康を犠牲にし、娯楽を犠牲にし、身を粉にして働き、その中の艱難辛苦は、わずかな筆致では万分の一も表現し尽くせない。様々な動員大会で、当時スローガンの中で叫ばれた「盤古必勝、華為必勝」という言葉に、我々の心は本当に深く感動したのだ。

しかし、我々のすべての苦労の成果は、しばしば小規模モデル実験室に軽々と奪われた。データは、直接奪取。コードは、直接奪取し、さらに我々にワンクリックで実行できるよう適応作業まで要求した。私たちは当時、小型モデル実験室を皮肉を込めて「マウスクリック実験室」と呼んでいた。我々が苦労を重ね、彼らが栄光を得る。まさにあの言葉通りだった「あなたが重荷を背負って前進しているのは、誰かがあなたの代わりに安穏とした日々を過ごしているからだ」。この状況下で、ますます多くの戦友がもはや耐えられず、退職を選択した。周りの優秀な同僚が一人また一人と退職するのを見て、私の内心は感嘆と悲しみに満ちた。この戦場のような環境下で、我々は同僚というより戦友に近い。彼らは技術面でも私が学ぶべき無数の価値があり、まさに良き師と呼べる存在だった。彼らが ByteDance Seed、DeepSeek、月之暗面（Kimi）、Tencent、Kuaishouなど多くの優秀なチームに行ったのを見て、私は心から彼らのために喜び祝福している。この辛いが汚れた場所から脱出したのだ。私は今でも一人の退職同僚の言葉を鮮明に覚えている。「ここに来たことは私の技術キャリアにおける恥辱だ。ここに一日でも長くいることは人生の無駄だ」。言葉は辛辣だが、私は反論できなかった。私は自分の技術面での蓄積不足と、IT企業の激しい競争環境に適応できるか心配で、何度も退職したいと思いながらも、この一歩を踏み出せずにいる。

盤古はDense型モデル以外に、後にMoEの探索も開始した。最初に学習したのは224BのMoEモデルだった。それと並行して、小型モデル実験室も第二次の主要な「套壳」行動（ガワだけ変える行為）を開始した（その他の小さなエピソードには、mathモデルなど他のモデルも含まれるかもしれない）。つまり、今回広く流布したpangu pro moe 72Bである。このモデルは内部では小型モデル実験室の7Bから拡張したと自称していた（仮にそうだとしても、これは技術報告書と矛盾している。ましてやQwen 2.5の14Bを継続訓練して「套壳」したものなのに）。覚えているのは、彼らが数日しか訓練していないのに、内部評価ですぐに当時の38B V3に追いついたことだ。AIシステム実験室の多くの仲間は、モデルの適応作業が必要なため、彼らの「套壳」行動を知っていたが、様々な理由により、正義を主張することができなかった。実際、その後非常に長い間訓練されたこのモデルについて、Honestagiがこのレベルの類似性を分析できたことに私はすでに驚いている。なぜなら、このモデルはパラメータを洗浄するための継続訓練に費やした計算リソースは、同じレベルのモデルを一から訓練するのに十分な量をとっくに超えていたからだ。同僚から聞いた話では、彼らは千問（Qianwen）のウォーターマークを洗い流すために多くの方法を採用し、わざと汚いデータで訓練することさえ含まれていたという。これは学術界にとって、モデルの血縁関係を研究する上で前例のない特殊な見本を提供したとも言えるだろう。今後新しい血縁関係の検証方法が提案されたら、これで試してみることができるだろう。

24年末と25年初、DeepSeek V3とR1発表後、その驚異的な技術水準により、チームは巨大な衝撃を受け、より大きな疑問も受けた。そこで潮流に追随するため、盤古はDeepSeekのモデルサイズを模倣し、7180億パラメータMoEの学習を開始した。この時、小規模モデル実験室が再度乗り出した。彼らはDeepSeek V3の偽装継続事前学習を選択した。彼らはDeepSeek読み込みパラメータを凍結して学習を行った。タスク読み込みチェックポイントのディレクトリまでdeepseekv3で、変更すらしない。何と傲慢な！それとは対照的に、一部の真の技術への信念を持つ同僚は、フルスクラッチで別の7180億パラメータMoEを学習していた。しかしその中で様々な問題が現れた。しかし明らかに、このモデルが直接偽装したものより良いはずがない。もしチームリーダーが断固として主張しなければ、とっくに中止されていただろう。

ファーウェイのプロセス管理の煩雑さは、大規模モデルの研究開発のペースを深刻に妨げている。例えば、バージョン管理、モデルの血縁関係、各種プロセス化、各種トレーサビリティなどだ。皮肉なことに、小型モデル実験室のモデルは、これらのプロセスの制約を受けたことがないようだ。「套壳」したければ「套壳」し、継続訓練したければ継続訓練し、計算リソースは絶え間なく手を伸ばして持っていく。この強烈で、ほとんど幻想的とも言える対比は、現在のプロセス管理の状況を物語っている。「役人の放火は許されるが、庶民の灯火は許されない」（権力者には特権があり、一般人には厳しい規則が適用される）。なんと可笑しいことか？なんと悲しいことか？なんと憎むべきことか？なんと恥ずべきことか！

HonestAGIの件が出た後、内部では皆に絶え間なく検討分析をさせ、いかに広報対応し「回答」するかを議論させた。確かに、その原文の分析は十分に有力ではなかったかもしれず、王雲鶴と小型モデル実験室に詭弁を弄し、黒白を転倒させる機会を与えてしまった。このため、この二日間、私は心の中で吐き気を感じ、自分の人生の意義と天に正義がないことを常に疑っている。私はもう付き合いきれない。離職する。同時に、盤古の一部の技術報告書の著者リストから私の名前を削除することも申請している。かつてこれらの技術報告書に署名したことは、私の一生涯消すことのできない汚点だ。当時、私は彼らがオープンソース化するほど猖獗を極めるとは思わなかった。彼らが世間をこれほど愚弄し、大々的に宣伝するとは思わなかった。当時、私は幸運を期待する心理があったのかもしれず、署名を拒否しなかった。多くの地道に仕事をしている戦友たちも、ただ強制的に賊船に乗せられたか、あるいは事情を知らなかっただけだと信じている。しかし、この件はもう取り返しがつかない。私は余生で、地道に真に意義のあることをし続け、当時の軟弱さと不確かさの罪を償いたいと願っている。

深夜ここまで書いて、私は既に涙が流れ、嗚咽で声も出ない。まだ一部の優秀な同僚が退職する時、私が苦笑いしながら彼らにお決まりの長い退職投稿を社内掲示板に出して現状を暴露しないかと尋ねたことを覚えている。相手は言った。「やらない、時間の無駄だし、暴露したらあなたたちがより辛い思いをするのも怖い。」私は当時一瞬暗澹とし、心を痛めた。かつて共に理想のために奮闘した戦友が既にファーウェイに完全に失望していたからだ。当時皆が冗談を言った。「我々は昔の共産党のお粗末な装備を使っているが、組織は昔の国民党に匹敵する体質を持っている。」と。

かつて私は、我々がお粗末な装備で米帝の最新兵器を打ち負かすことを誇りに思った。

今、私は疲れた、私は降伏したい。

実は今日に至っても、私は心から華為が真剣に教訓を汲み取り、盤古をしっかりと作り、世界一流のレベルに到達させ、昇騰をNVIDIAのレベルにまで引き上げることができることを願っている。内部で「悪貨が良貨を駆逐する」状況により、ノアひいてはファーウェイは短期間で急激に大量の優秀な大規模言語モデル人材を失った。彼らはDeepSeekなど各チームで輝き、その志と才能を発揮し、米中AI激烈競争で力を貢献していると信じている。私はしばしば感嘆する。ファーウェイには人材がいないのではなく、人材を引き留める方法を全く知らないのだ。もしこれらの人々に適切な環境、適切なリソース、より少ない足かせ、より少ない政治闘争を与えれば、盤古が成功しないはずがない。

最後に。私は生命、人格、名誉にかけて誓う。私が書いた以上の全ての内容は真実である（少なくとも私の限られた認識範囲において）。私にはそれほど高い技術レベルも、詳細で確実な分析を行う機会もなく、情報セキュリティで捕まることを恐れて内部記録を直接証拠として使うこともできない。しかし、私のかつての多くの戦友たちが、私のために証言してくれると信じている。
ファーウェイ内部の仲間たち、私たちがかつてサービスを提供した製品ラインの仲間たちを含め、本文の無数の詳細が皆さんの印象と照合でき、私の言葉を裏付けると信じている。皆さんもかつて欺かれていたかもしれないが、これらの残酷な真相は封印されることはない。私たちが奮闘した痕跡も、歪曲され埋葬されるべきではない

これほど多く書いたが、一部の人々は必ず私を見つけ出し、口封じしたがるだろう。会社も恐らく私を沈黙させ、さらには責任追及したがるだろう。もし本当にそうなら、私、ひいては私の家族の身の安全、さらには生命の安全も脅威を受ける可能性がある。自己保護のため、私は近々毎日皆に安否報告をする。

もし私が姿を消したら、私が真理と理想のため、ファーウェイひいては中国の計算資源とAIのより良い発展のために犠牲になったと思ってほしい。私はかつて奮闘したあの土地に埋葬されたい。

ノア、さらば

2025年7月6日未明　深圳にて
